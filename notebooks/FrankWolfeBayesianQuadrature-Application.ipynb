{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas_datareader import data\n",
    "from math import exp, log, pi, sqrt, cos, sin\n",
    "from copy import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying Frank-Wolfe Line-Search Bayesian Quadrature in finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the instruments to download. We would like to see Apple, Microsoft and Google.\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"FB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we would like all available data from 01/01/2000 until 12/31/2016.\n",
    "startdate = \"2018-01-01\"\n",
    "enddate = \"2018-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "paneldata = data.DataReader(tickers, 'yahoo', startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paneldata.head()\n",
    "print(paneldata.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting just the adjusted closing prices.\n",
    "close = paneldata[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting all weekdays between 01/01/2000 and 12/31/2018\n",
    "allweekdays = pd.date_range(start=startdate, end=enddate, freq='B')\n",
    "\n",
    "# how do we align the existing prices in adjclose with our new set of dates?\n",
    "# all we need to do is reindex close using allweekdays as the new index\n",
    "close = close.reindex(allweekdays)\n",
    "\n",
    "# reindexing will insert missing values (nan) for the dates that were not present\n",
    "# in the original set. To cope with this, we can fill the missing by replacing them\n",
    "# with the latest available price for each instrument\n",
    "close = close.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the Data\n",
    "close.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating the returns\n",
    "returns = close.pct_change(periods = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(close.head())\n",
    "print(returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "returns = returns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = np.mean(a = returns, axis = 0).tolist()\n",
    "COV = np.cov(returns.transpose())\n",
    "COR = np.corrcoef(returns.transpose())\n",
    "# print(MU)\n",
    "print(COR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = []\n",
    "C.append(close[\"AAPL\"].tolist()[-1])\n",
    "C.append(close[\"GOOG\"].tolist()[-1])\n",
    "C.append(close[\"MSFT\"].tolist()[-1])\n",
    "C.append(close[\"FB\"].tolist()[-1])\n",
    "# print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(COR, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": 0.6})\n",
    "\n",
    "plt.savefig(\"plot-application-covariance.png\", dpi = 100, bbox_inches =\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock price evolution is modelled by the following stochastic differential equation : $$ dS(t) = \\mu dS_t + \\sigma S_t dB(t) $$ where $S$ is the asset price, $\\mu$ is the drift, $\\sigma$ is the volatility and $B$ is a Brownian motion (which can be thought as $dB(t) \\hookrightarrow N(0, dt)$). Let $r$ be the risk-free rate. After using Ito's Lemma to get an expression of $d\\text{log}S_t$, the solution is given by : $S(t) = S(0) \\text{exp} ((r-\\frac{1}{2}\\sigma^2)t + \\sigma \\sqrt{t} N(0, 1) )$. In the case where we are studying a basket of $d$ assets, $S_{(i)}(t) = S_{(i)}(0) \\text{exp} ((r-\\frac{1}{2}\\sigma_{(i)}^2)t + \\sigma \\sqrt{t} W_{(i)} )$ for $i \\in \\{0, ..., d-1\\}$ where the vector $W$ = $(W_{(0)}, ..., W_{(d-1)})$ follows a multivariate normal distribution with mean $MU = (0, ..., 0)$ and with a covariance matrix $COR$ which is in fact the correlation matrix between assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate random (returns-)correlated assets\n",
    "\n",
    "number = COV.shape[0]\n",
    "assert(COV.shape[0] == COV.shape[1])\n",
    "N = 500\n",
    "W = stats.multivariate_normal(mean = [0 for i in range(number)], cov = COR).rvs(N)\n",
    "t = 10 # days\n",
    "\n",
    "X = []\n",
    "r = 0.5/100\n",
    "\n",
    "for i in range(number):\n",
    "    X.append( C[i]*np.exp( (r-1/2*COV[i][i])*t + np.sqrt(COV[i][i]) * np.sqrt(t) * W[:,i]) )\n",
    "\n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "# set up the matplotlib figure\n",
    "f, axes = plt.subplots(2, 2, figsize=(12, 12), sharex=True)\n",
    "# sns.despine(left=True)\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(X[0], hist=True, color=\"g\", kde_kws={\"shade\": False})\n",
    "plt.xlabel(tickers[0])\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.distplot(X[1], hist=True, color=\"g\", kde_kws={\"shade\": False})\n",
    "plt.xlabel(tickers[1])\n",
    "\n",
    "plt.subplot(223)\n",
    "sns.distplot(X[2], hist=True, color=\"g\", kde_kws={\"shade\": False})\n",
    "plt.xlabel(tickers[2])\n",
    "\n",
    "plt.subplot(224)\n",
    "sns.distplot(X[3], hist=True, color=\"g\", kde_kws={\"shade\": False})\n",
    "plt.xlabel(tickers[3])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the payoff of a basket option : $$ \\mathbb{E}_P \\Big( f(S(T)) \\Big) = \\int f(s) p(s) ds $$ where for example $f(x) = \\text{max} ( \\sum_{i = 1}^{d} \\alpha_{(i)} x_{(i)} - K, 0) $ with $K = \\sum_{i = 1}^{d} \\alpha_{(i)} S_{(i)}(0) $.\n",
    "\n",
    "The idea is to approximate this expectancy by the one given by FWLSBQ : $$ \\mathbb{E}_P \\Big( f(S(T)) \\Big) \\simeq \\sum_{i = 1}^{N} w_{(i)}^{BQ} f(S_{(i)}^{FW}(T))) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of FWLSBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# univariate and multivariate normal probability density function\n",
    "univariatepdf = stats.norm.pdf\n",
    "multivariatepdf = stats.multivariate_normal.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimension = dim\n",
    "dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters of the probability density function p\n",
    "mixmus = [\n",
    "    np.zeros(dim)\n",
    "]\n",
    "mixsigmas = [\n",
    "    COR\n",
    "]\n",
    "mixweights = [\n",
    "    1.00\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample according to p\n",
    "def sample(mixmus, mixsigmas, mixweights, n):\n",
    "    indexes = np.random.choice(len(mixweights), size=n, p=mixweights)\n",
    "    L = mixmus[0].shape[0]\n",
    "    A = np.zeros((n, L))\n",
    "    for i, ix in enumerate(indexes):\n",
    "        A[i, :] = stats.multivariate_normal.rvs(mixmus[ix], mixsigmas[ix])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function f\n",
    "def f(x):\n",
    "    d = len(x)\n",
    "    w = np.ones(d)/d\n",
    "    t = 10\n",
    "    r = 0.5/100\n",
    "    S = 0\n",
    "    for i in range(d):\n",
    "        S += w[i] * C[i]*np.exp( (r-1/2*COV[i][i])*t +\n",
    "                    np.sqrt(COV[i][i]) * np.sqrt(t) * x[i] )\n",
    "    K = np.sum(w * C)\n",
    "    return( np.max(S - K, 0) )\n",
    "    # return( S - K )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example, draw 6 points according to p\n",
    "X = sample(mixmus = mixmus, mixsigmas = mixsigmas, mixweights = mixweights, n = 6)\n",
    "for i in range(X.shape[0]):\n",
    "    print(X[i,:], f(X[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 # number of points to draw at each iteration\n",
    "m = 1 # number of iterations\n",
    "I = []\n",
    "for i in range(m):\n",
    "    A = 0\n",
    "    points = sample(mixmus, mixsigmas, mixweights, n = n)\n",
    "    for j in range(n):\n",
    "        weight = 1/n\n",
    "        point = points[j,:]\n",
    "        # print(point, f(point))\n",
    "        A += weight*f(point)\n",
    "    I.append(A)\n",
    "print(\"Monte Carlo integration : \", sum(I)/len(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frank-Wolfe Least Squares Bayesian Quadrature integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100 # number of points to draw\n",
    "lambda_ = 1\n",
    "sigma_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reproducing kernel k (RKHS)\n",
    "def kernel(a, b, lambda_, sigma_):\n",
    "    cov = sigma_**2 * np.eye(dim)\n",
    "    return( lambda_ * lambda_ * (np.sqrt(2*pi)*sigma_)**(dim) * multivariatepdf(a.ravel(), b.ravel(), cov) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-dimensional mean map kernel\n",
    "def simplemeanmapkernel(x, mu, sigma, lambda_, sigma_):\n",
    "    cov = sigma_**2 * np.eye(dim)\n",
    "    # np.linalg.det(sigma) = sigma\n",
    "    # np.linalg.inv(sigma) = sigma\n",
    "    return( lambda_ * lambda_ * (np.sqrt(2*pi)*sigma_)**(dim) * multivariatepdf(x.ravel(), mu.ravel(), sigma + cov) )\n",
    "# two-dimensional mean map kernel\n",
    "def mixturemeanmapkernel(x, mus, sigmas, mixweights, lambda_, sigma_):\n",
    "    mixture = np.array([simplemeanmapkernel(x, mu1, sigma1, lambda_, sigma_) for mu1, sigma1 in zip(mus, sigmas)])\n",
    "    return np.sum(mixweights * mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# canonical feature map for a given x\n",
    "def phi(x, lambda_, sigma_):\n",
    "    def atom(a):\n",
    "        return(kernel(a, x, lambda_, sigma_))\n",
    "    return(atom)\n",
    "# function to compute the successive g\n",
    "def psi(rho, a, b):\n",
    "    def g(x):\n",
    "        return((1-rho) * a(x) + rho * b(x))\n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "# model = \"FWBQ\"\n",
    "model = \"FWLSBQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start for rho, line-search\n",
    "if model == \"FWBQ\":\n",
    "    rho = [1/(i+1) for i in range(0, n)]\n",
    "    print(\"model is FWBQ\")\n",
    "elif model == \"FWLSBQ\":\n",
    "    rho = [1/(i+1) for i in range(0, 1)]\n",
    "    print(\"model is FWLSBQ\")\n",
    "else:\n",
    "    print(\"model has to be either FWLSBQ or FWBQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanmapkernel = lambda x: mixturemeanmapkernel(x, mixmus, mixsigmas, mixweights, lambda_, sigma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integral of the mean map kernel\n",
    "def integralmeanmapkernel(mixmus, mixsigmas, mixweights, lambda_, sigma_):\n",
    "    cov = sigma_**2 * np.eye(dim)\n",
    "    L = len(mixweights)\n",
    "    c = lambda_ * lambda_ * (np.sqrt(2*pi)*sigma_)**(dim)\n",
    "    a = 0\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            a = a + mixweights[i] * mixweights[j] * multivariatepdf(x = mixmus[i].ravel(), mean = mixmus[j].ravel(), cov = mixsigmas[i] + mixsigmas[j] + cov)\n",
    "    return(c * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 1 // FW (Frank-Wolfe) algorithm\n",
    "\n",
    "# store information in a dictionary\n",
    "dico = {} # dictionnary to store at each iteration : point(i), weight(i), g(i)\n",
    "i = 1\n",
    "print(\"{0} / {1}\".format(i, n), end = '\\r')\n",
    "W = [np.nan]\n",
    "for l in range(1, i+1):\n",
    "    w = 1\n",
    "    for j in range(l+1, i+1):\n",
    "        w = w * (1-rho[j-1])\n",
    "    w = w * rho[l-1]\n",
    "    W.append(w)\n",
    "X = sample(mixmus, mixsigmas, mixweights, n = 1) # draw the first point randomly\n",
    "dico[i] = {\"point\" : X[0], \"weight\" : W}\n",
    "dico[i][\"function\"] = phi(dico[i][\"point\"], lambda_, sigma_)\n",
    "g = phi(dico[i][\"point\"], lambda_, sigma_)\n",
    "dico[i][\"g\"] = g\n",
    "\n",
    "for i in range(2, n+1):\n",
    "\n",
    "    print(\"{0} / {1}\".format(i, n), end = '\\r')\n",
    "\n",
    "    # step1 ) computing a new point\n",
    "\n",
    "    # T is the function to minimize\n",
    "    def T(x, i, kernel, meanmapkernel):\n",
    "        s = 0\n",
    "        for j in range(1, i):\n",
    "            w = dico[i-1][\"weight\"][j]\n",
    "            c = dico[j][\"point\"]\n",
    "            s = s + ( w * kernel(x, c, lambda_, sigma_) )\n",
    "        s = s - meanmapkernel(x)\n",
    "        return(s)\n",
    "\n",
    "    # samplepoints to find the minimum among them\n",
    "    if i > 1:\n",
    "        samplepoints1 = sample(mixmus, mixsigmas, mixweights, n = 5000)\n",
    "\n",
    "    # start = clock()\n",
    "    # find the minimum X\n",
    "    Xmin = samplepoints1[0]\n",
    "    Tmin = T(x = Xmin, i = i, kernel = kernel, meanmapkernel = meanmapkernel)\n",
    "    for X in samplepoints1:\n",
    "        t = T(x = X, i = i, kernel = kernel, meanmapkernel = meanmapkernel)\n",
    "        if t < Tmin:\n",
    "            Xmin = X\n",
    "            Tmin = t\n",
    "    X = Xmin\n",
    "    # X = samplepoints1[np.argmin([T(x, i, kernel, meanmapkernel) for x in samplepoints1])]\n",
    "    # end = clock()\n",
    "    # print(end - start, \"\\n\")\n",
    "\n",
    "    # step 2 ) computing the weights for the next iteration\n",
    "\n",
    "    if model == \"FWLSBQ\":\n",
    "        # compute the matrix K\n",
    "        K = np.zeros(shape = (i-1, i-1))\n",
    "        for c in range(i-1):\n",
    "            for d in range(i-1):\n",
    "                Xc = dico[c+1][\"point\"]\n",
    "                Xd = dico[d+1][\"point\"]\n",
    "                K[c][d] = kernel(Xc, Xd, lambda_, sigma_)\n",
    "\n",
    "        first = np.dot(np.dot([W[1:]], K), W[1:])\n",
    "        second = 0\n",
    "        weightedmeanmap = 0\n",
    "        for r in range(1, i-1+1):\n",
    "            point = dico[r][\"point\"] # point\n",
    "            weight = W[r] # weight\n",
    "            second += weight * kernel(point, X, lambda_, sigma_)\n",
    "            weightedmeanmap += weight * meanmapkernel(point)\n",
    "        numerator = first - second - weightedmeanmap + meanmapkernel(X)\n",
    "        denominator = first - 2 * second + kernel(X, X, lambda_, sigma_)\n",
    "        rho.append(float(numerator / denominator))\n",
    "\n",
    "    W = [np.nan]\n",
    "    for l in range(1, i+1):\n",
    "        w = 1\n",
    "        for j in range(l+1, i+1):\n",
    "            w = w * (1-rho[j-1])\n",
    "        w = w * rho[l-1]\n",
    "        W.append(w)\n",
    "\n",
    "    dico[i] = {\"point\" : X, \"weight\" : W}\n",
    "    dico[i][\"function\"] = phi(dico[i][\"point\"], lambda_, sigma_)\n",
    "\n",
    "    # step 3 ) computing the mean element\n",
    "    g = psi(rho = rho[-1], a = g, b = dico[i][\"function\"])\n",
    "    dico[i][\"g\"] = g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 // BQ (Bayesian Quadrature) algorithm\n",
    "\n",
    "# compute the vector Z\n",
    "Z = np.zeros(shape = (n, 1))\n",
    "for i in range(n):\n",
    "    Xi = dico[i+1][\"point\"]\n",
    "    Z[i][0] = meanmapkernel(Xi)\n",
    "\n",
    "# compute the matrix K\n",
    "K = np.zeros(shape = (n, n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        Xi = dico[i+1][\"point\"]\n",
    "        Xj = dico[j+1][\"point\"]\n",
    "        K[i][j] = kernel(Xi, Xj, lambda_, sigma_)\n",
    "# compute the inverse of the matrix K\n",
    "INVK = np.linalg.inv(K)\n",
    "\n",
    "# Frank-Wolfe weights\n",
    "WFW = W[1:]\n",
    "print(\"sum of Frank-Wolfe weights = \", sum(WFW))\n",
    "\n",
    "# Bayesian Quadrature weights\n",
    "WBQ = np.dot(Z.transpose(), INVK)[0]\n",
    "print(\"sum of Bayesian Quadrature weights = \", sum(WBQ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 // posterior mean, equation (4) in the article\n",
    "\n",
    "# compute the vector F\n",
    "F = np.zeros(shape = (n, 1))\n",
    "for i in range(n):\n",
    "    Xi = dico[i+1][\"point\"]\n",
    "    F[i][0] = f(Xi)\n",
    "\n",
    "# compute the posterior mean\n",
    "mean = np.float(np.dot(np.dot(Z.transpose(), INVK), F))\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 // posterior variance, equation (5) in the article\n",
    "\n",
    "variance1 = integralmeanmapkernel(mixmus = mixmus, mixsigmas = mixsigmas, mixweights = mixweights, lambda_ = lambda_, sigma_ = sigma_)\n",
    "variance2 = np.float(np.dot(np.dot(Z.transpose(), INVK), Z))\n",
    "variance = variance1 - variance2\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectedpoints = np.matrix(data = np.zeros(n*dim).reshape(n, dim))\n",
    "i = 0\n",
    "for x in dico.items():\n",
    "    selectedpoints[i,:] = x[1][\"point\"]\n",
    "    i = i+1\n",
    "\n",
    "selectedpoints = np.array(selectedpoints)\n",
    "\n",
    "# print(selectedpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 // full posterior (normal distribution)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "X_ = np.linspace(start = mean-6*np.sqrt(variance), stop = mean+6*np.sqrt(variance), num = 1000)\n",
    "Y_ = univariatepdf(x = X_, loc = mean, scale = np.sqrt(variance))\n",
    "plt.plot(X_, Y_, color = \"orange\")\n",
    "plt.vlines(x = mean, ymin = 0, ymax = max(Y_), color = \"black\", linestyles = \"dotted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "\n",
    "print(\" Monte Carlo integration \\t \\t \\t \\t \\t =\", float(sum(I)/len(I)), \"\\n\",\n",
    "\"Frank-Wolfe Line-Search integration \\t \\t \\t \\t =\", float(np.float(np.dot(W[1:], F))), \"\\n\",\n",
    "\"Frank-Wolfe Line-Search Bayesian Quadrature integration \\t =\", float(mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the vector G\n",
    "G = np.zeros(shape = (n, n))\n",
    "for i in range(n):\n",
    "    print(\"{0} / {1}\".format(i+1, n), end = '\\r')\n",
    "    gi = dico[i+1][\"g\"]\n",
    "    for j in range(i+1):\n",
    "        G[j,i] = gi(dico[j+1][\"point\"])\n",
    "print(G[:4,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(F.shape)\n",
    "# print(Z.shape)\n",
    "# print(K.shape)\n",
    "\n",
    "start = 5\n",
    "\n",
    "FWLS_mean = []\n",
    "FWLSBQ_mean = []\n",
    "FWLS_variance = []\n",
    "FWLSBQ_variance = []\n",
    "\n",
    "index = []\n",
    "index.append(start)\n",
    "x = start\n",
    "while x < n+1:\n",
    "    index.append(x)\n",
    "    x += 5\n",
    "    \n",
    "I0 = index\n",
    "    \n",
    "for i in index:\n",
    "    print(\"{0} / {1}\".format(i, n), end = '\\r')\n",
    "    Gi = G[0:i,i-1].reshape(i, 1)\n",
    "    Zi = Z[0:i,:]\n",
    "    Fi = F[0:i,:]\n",
    "    Ki = K[0:i,0:i]\n",
    "    \n",
    "    WeightsFW = dico[i][\"weight\"][1:]\n",
    "    \n",
    "    WeightsBQ = np.dot(Zi.transpose(), np.linalg.inv(Ki))\n",
    "    \n",
    "    MeanFW = np.float(np.dot(WeightsFW, Fi))\n",
    "    \n",
    "    MeanBQ = np.float(np.dot(WeightsBQ, Fi))\n",
    "    \n",
    "#     variance1 = integralmeanmapkernel(mixmus = mixmus, mixsigmas = mixsigmas, mixweights = mixweights, lambda_ = lambda_, sigma_ = sigma_)\n",
    "#     variance2 = np.float(np.dot(WeightsFW, Gi))\n",
    "#     variance = variance1 - variance2\n",
    "    variance = np.sum(np.square(Gi - Zi))\n",
    "    VarianceFW = abs(variance)\n",
    "    \n",
    "    variance1 = integralmeanmapkernel(mixmus = mixmus, mixsigmas = mixsigmas, mixweights = mixweights, lambda_ = lambda_, sigma_ = sigma_)\n",
    "    variance2 = np.float(np.dot(WeightsBQ, Zi))\n",
    "    variance = variance1 - variance2\n",
    "    VarianceFWBQ = abs(variance)\n",
    "    \n",
    "    FWLS_mean.append(MeanFW)\n",
    "    FWLSBQ_mean.append(MeanBQ)\n",
    "    FWLS_variance.append(VarianceFW)\n",
    "    FWLSBQ_variance.append(VarianceFWBQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 6)\n",
    "\n",
    "if model == \"FWBQ\":\n",
    "    algo1 = \"FW\"\n",
    "    algo2 = \"FWBQ\"\n",
    "elif model == \"FWLSBQ\":\n",
    "    algo1 = \"FWLS\"\n",
    "    algo2 = \"FWLSBQ\"\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "X1 = I0\n",
    "Y1 = FWLS_variance\n",
    "Y2 = FWLSBQ_variance\n",
    "\n",
    "line1, = plt.plot(X1, Y1, color = \"orange\", label = algo1)\n",
    "line2, = plt.plot(X1, Y2, color = \"red\", label = algo2)\n",
    "plt.xlabel(r\"iterations / number of selected points\", fontsize = 14)\n",
    "plt.ylabel(r\"MMD$^2$\", fontsize = 14)\n",
    "plt.legend(handles=[line1, line2], fontsize = 15, loc = 'upper right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "X0 = I0\n",
    "Y0 = FWLSBQ_mean\n",
    "Y01 = FWLSBQ_mean-1.96*np.sqrt(FWLSBQ_variance)\n",
    "Y02 = FWLSBQ_mean+1.96*np.sqrt(FWLSBQ_variance)\n",
    "line0, = plt.plot(X0, Y0, color = \"red\", label = algo2)\n",
    "plt.fill_between(I0, Y01, Y02, color = \"lightgrey\")\n",
    "plt.xlabel(r\"iterations / number of selected points\", fontsize = 14)\n",
    "plt.ylabel(r\"value of the integral\", fontsize = 14)\n",
    "plt.legend(handles=[line0], fontsize = 15, loc = 'lower right')\n",
    "\n",
    "plt.savefig(\"plot-application-mmdsquared-value-\"+model+\".png\", dpi = 100, bbox_inches =\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
