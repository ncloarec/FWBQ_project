% Encoding: UTF-8

@Article{FWBQ,
  author       = {François-Xavier Briol and Chris J. Oates and Mark Girolami and Michael A. Osborne},
  title        = {Frank-Wolfe Bayesian Quadrature: Probabilistic Integration with Theoretical Guarantees},
  abstract     = {There is renewed interest in formulating integration as an inference problem, motivated by obtaining a full distribution over numerical error that can be propagated through subsequent computation. Current methods, such as Bayesian Quadrature, demonstrate impressive empirical performance but lack theoretical analysis. An important challenge is to reconcile these probabilistic integrators with rigorous convergence guarantees. In this paper, we present the first probabilistic integrator that admits such theoretical treatment, called Frank-Wolfe Bayesian Quadrature (FWBQ). Under FWBQ, convergence to the true value of the integral is shown to be exponential and posterior contraction rates are proven to be superexponential. In simulations, FWBQ is competitive with state-of-the-art methods and out-performs alternatives based on Frank-Wolfe optimisation. Our approach is applied to successfully quantify numerical error in the solution to a challenging model choice problem in cellular biology.},
  date         = {2015-06-08},
  eprint       = {https://arxiv.org/pdf/1506.02681.pdf},
  eprintclass  = {stat.ML},
  eprinttype   = {arXiv},
  file         = {:http\://arxiv.org/pdf/1506.02681v3:PDF},
  journaltitle = {Advances in Neural Information Processing Systems 28, 1162--1170, 2015},
  keywords     = {stat.ML},
}

@Unpublished{duvenaud,
  author = {David Duvenaud},
  title  = {Bayesian Quadrature: Model-based Approximate Integration},
  url    = {https://www.cs.toronto.edu/~duvenaud/talks/intro_bq.pdf},
  Howpublished = {University Lecture},
  Institution = {University of Cambridge},
}

@Article{huszar,
  author      = {Ferenc Huszár and David Duvenaud},
  title       = {Optimally-Weighted Herding is Bayesian Quadrature},
  abstract    = {Herding and kernel herding are deterministic methods of choosing samples which summarise a probability distribution. A related task is choosing samples for estimating integrals using Bayesian quadrature. We show that the criterion minimised when selecting samples in kernel herding is equivalent to the posterior variance in Bayesian quadrature. We then show that sequential Bayesian quadrature can be viewed as a weighted version of kernel herding which achieves performance superior to any other weighted herding method. We demonstrate empirically a rate of convergence faster than O(1/N). Our results also imply an upper bound on the empirical error of the Bayesian quadrature estimate.},
  date        = {2012-04-07},
  eprint      = {https://arxiv.org/pdf/1204.1664.pdf},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1204.1664v3:PDF},
  keywords    = {stat.ML, math.NA, G.1.4},
}

@Comment{jabref-meta: databaseType:bibtex;}
